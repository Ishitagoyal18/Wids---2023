{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OSeJ-R-y9s7"
   },
   "source": [
    "# Linear Regression\n",
    "\n",
    "Linear regression analysis is used to predict the value of a variable based on the value of another variable. The variable you want to predict is called the dependent variable. The variable you are using to predict the other variable's value is called the independent variable\n",
    "\n",
    "This week, your task involves conducting multi-class linear regression on batsmen salaries. You'll use the average runs scored per game and the strike rate as independent variables. The goal is to predict the salary as the dependent variable. Additionally, you'll be categorizing the data based on the years.\n",
    "\n",
    "The dataset is Data_Mendeley.csv given on GitHub. Feel free to create any new functions required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AZ77VEImzRW5"
   },
   "outputs": [],
   "source": [
    "#import important libraries\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n"
    "from sklear.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oQPpSttzqt6"
   },
   "source": [
    "preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NgyvUuEMAVEr"
   },
   "outputs": [],
   "source": [
    "#mounting gdrive\n",
    "df=pd.read_csv(\"Data_Mendeley.csv\")\n",
    "x= np.array(df[['Runs','StrRate']])\n",
    "y= np.array(df['Final Price'])\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state =1234)\n",
    "sc=StandardScaler\n",
    "x_train= sc.fit_trasform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
     
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9C0MZOGzg7g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LV9ROCrR1hQ5"
   },
   "source": [
    "Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AgySD6Ac1DCw"
   },
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3uHaq5x1i7p"
   },
   "source": [
    "Mean Squared Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eP2rV0z21IaN"
   },
   "outputs": [],
   "source": [
    "def loss(y,y_pred): \n",
    "    #Mean Squared Loss\n",
    "    msl=np.mean((y-y_pred)**2)\n",
    "    return msl\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JoKzzr_1uvt"
   },
   "source": [
    "Implement Linear regression here :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "k2W3q6eR1d2J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan]\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self,lr=0.001,n_iterations=1000):\n",
    "        self.lr=lr\n",
    "        self.n_iterations=n_iterations\n",
    "        self.weights=None\n",
    "        self.bias=None\n",
    "\n",
    "    def fit(self,x,y):\n",
    "        n_samples,n_features=x.shape\n",
    "        self.weights=np.zeros(n_features)\n",
    "        \n",
    "        self.bias=0\n",
    "        \n",
    "        for _ in range(self.n_iterations):\n",
    "          y_pred= np.dot(x,self.weights) + self.bias\n",
    "          \n",
    "          dw=(1/n_samples)*np.dot(x.T,(y_pred-y))\n",
    "          db= (1/n_samples)*np.sum(y_pred-y)\n",
    "          self.weights = self.weights - self.lr*dw\n",
    "          self.bias=self.bias- self.lr*db\n",
    "        print(self.weights)\n",
    "        print(self.bias)\n",
    "    def predict(self,x):\n",
    "        y_pred= np.dot(x,self.weights) + self.bias\n",
    "        return y_pred\n",
    "lreg= LinearRegression()\n",
    "lreg.fit(x_train,y_train)\n",
    "y_pred= lreg.predict(x_test)\n",
    "print(loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTAky_OS1w0P"
   },
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Logistic regression is a process of modeling the probability of a discrete outcome given an input variable. The most common logistic regression models a binary outcome; something that can take two values such as true/false, yes/no, and so on.\n",
    "\n",
    "In this week you will be doing logistic regression on breast cancer dataset using sklearn library. Feel free to create any new functions required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "E56ck0_P2NR9"
   },
   "outputs": [],
   "source": [
    "#importinf libraries\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qojSAol72cmH"
   },
   "source": [
    "Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_uUSV8Xk2ePh"
   },
   "outputs": [],
   "source": [
    "breast_cancer = datasets.load_breast_cancer()\n",
    "X, y = breast_cancer.data, breast_cancer.target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "N6jcbk5g29XW"
   },
   "outputs": [],
   "source": [
    "#spliting data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofghhz-63Ru5"
   },
   "source": [
    "Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "K1JzUVko3Zob"
   },
   "outputs": [],
   "source": [
    "def forward_log(x):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4ldHUJs3d2V"
   },
   "source": [
    "Binary cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QkXgo04D3dGW"
   },
   "outputs": [],
   "source": [
    "def BCELoss(y,y_pred):\n",
    "    \n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIuuOJcJ3sti"
   },
   "source": [
    "Implement Logistic Regression here :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gBJ6H_ss3yUr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "    \n",
    "\n",
    "\n",
    "class LogisticRegression():\n",
    "\n",
    "    def __init__(self , lr=0.001 , n_iterations=1000 ):\n",
    "        #lr can be  variable\n",
    "        self.lr = lr\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self , X , y ):\n",
    "        n_samples , n_features = X.shape\n",
    "        self.weights =  np.zeros(n_features)\n",
    "        \n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.n_iterations):\n",
    "            Linear_predictions = np.dot(X , self.weights) + self.bias\n",
    "            predictions = sigmoid(Linear_predictions)\n",
    "\n",
    "            dw = (1/n_samples) * np.dot(X.T , (predictions - y)) \n",
    "            db = (1/n_samples) * np.sum(predictions - y)\n",
    "        \n",
    "            self.weights = self.weights - self.lr*dw\n",
    "            self.bias = self.bias - self.lr*db \n",
    "    def predict(self , X):\n",
    "        Linear_predictions = np.dot(X , self.weights) + self.bias            \n",
    "        y_predictions = sigmoid(Linear_predictions)\n",
    "        class_pred = [0 if y  <= 0.5 else 1 for y in y_predictions]\n",
    "        return class_pred\n",
    "reg=LogisticRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "y_pred=reg.predict(X_test)\n",
    "def accuracy(y_test,y_pred):\n",
    "    return np.sum(y_test==y_pred)/len(y_test)\n",
    "\n",
    "print(accuracy(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
